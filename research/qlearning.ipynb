{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7fb2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_states = 16\n",
    "n_actions = 4\n",
    "goal_state = 15\n",
    "\n",
    "Q_table = np.zeros((n_states,n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2a1403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db50279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.8\n",
    "# Low discount factor means that I only care about immediate rewards whereas high discount factor means that I care about future rewards \n",
    "# A simple example would be if I pick the coin in front of me or I take a risky path that could lead to future rewards\n",
    "discount_factor = 0.95\n",
    "exploration_prob = 0.2\n",
    "# An epoch means that the model has passed through an entire phase of learning with all the available training data. \n",
    "# If there are 100 training data samples, then one epoch is when your model trains from all 100 once.\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a575829",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    current_state = np.random.randint(0,n_states)\n",
    "    while current_state != goal_state:\n",
    "        # Here the reason we have this set up in this way is because we try to balance exploration vs exploitation\n",
    "        # Here we arent manually defining wether to explore or exploit, rather we are deciding it based on a random value \n",
    "        # \"np.random.rand() < exploration_prob\"\n",
    "        # So if it is less than exploration proabability then explore else exploit.\n",
    "        if np.random.rand() < exploration_prob:\n",
    "            action = np.random.randint(0, n_actions)\n",
    "        else:\n",
    "            action = np.argmax(Q_table[current_state])\n",
    "        # move to the next state, or wrap around -> used in circular queue\n",
    "        next_state = ( current_state + 1 ) % n_states\n",
    "        reward = 1 if next_state == goal_state else 0\n",
    "        Q_table[current_state,action] += learning_rate * (reward + discount_factor * np.max(Q_table[next_state]) - Q_table[current_state, action])\n",
    "        \n",
    "        current_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2809052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47956544 0.4868947  0.39013998 0.48767498]\n",
      " [0.51334178 0.51334208 0.51334077 0.51333551]\n",
      " [0.54035978 0.5403587  0.54036009 0.54018717]\n",
      " [0.56880009 0.56880009 0.56879864 0.56880009]\n",
      " [0.59873694 0.59873694 0.59873694 0.59873694]\n",
      " [0.63024941 0.63024941 0.63024941 0.63024941]\n",
      " [0.66342043 0.66342043 0.66342043 0.66342043]\n",
      " [0.6983373  0.6983373  0.6983373  0.6983373 ]\n",
      " [0.73509189 0.73509189 0.73509189 0.73509189]\n",
      " [0.77378094 0.77378094 0.77378094 0.77378094]\n",
      " [0.81450625 0.81450625 0.81450625 0.81450625]\n",
      " [0.857375   0.857375   0.857375   0.857375  ]\n",
      " [0.9025     0.9025     0.9025     0.9025    ]\n",
      " [0.95       0.95       0.95       0.95      ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Q_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
